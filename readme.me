ðŸ§  Welcome to the LLM Explorer! ðŸš€

My goal is to guide you in using LLMs to create applications.
I aim for you to grasp the concepts step by step. Baby steps.
If you find any concept challenging or feel that I made a leap too big,
let me know and I'll break it down into smaller, more manageable parts.


Whether youâ€™re a beginner or an experienced developer,
this repo will take you through the foundational concepts,
practical implementations, and advanced techniques,
with a focus on tools like LangChain, knowledge graphs, RAG (Retrieval-Augmented Generation), and much more.

1-chatgpt basic example
2-lang-chain basic usage of the langchain library
3-streaming basic usage of the streaming callback handler
4-two-chains basic usage of two chains in langchain 
5-two-chains-composition builds on the two-chains example by demonstrating how to compose multiple chains together for more complex workflows.
6-simpler-templates introduces simpler templates for creating prompts, making it easier to customize and reuse them.
7-batch-multi-model shows how to handle batch processing with multiple models, improving efficiency and scalability.
8-async explores asynchronous processing techniques to enhance performance and responsiveness.
9-crawler provides an example of a web crawler that leverages LLMs for extracting and processing information from websites.
10-embed provides an example of how to use embeddings to create a vector database.
11-rag provides an example of how to use RAG, vector databases, and FAISS to create a vector database.
12-poor-mans-vector-db demonstrates a simple in-memory vector database implementation for semantic search capabilities.
13-rag shows how to implement Retrieval Augmented Generation using vector stores and LLMs.
14-form shows how to create a simple chat interface with a form and a single LLM using streams.
15-form-two-llms shows how to create a simple chat interface with two LLMs using streams.



next:

agents
lang-graph
llm integration
hummus bot 

# how to install ollama
brew install ollama
ollama serve
ollama run llama2 "Hello, how are you?"

# git diff --cached | ollama run llama3.2 "what changed? phrase it in a 10 words so i can use it for the commit message. i want you to output just these words - the message will be piped immediately to git"


